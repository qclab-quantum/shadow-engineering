{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164bda8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import vmap\n",
    "import pandas as pd\n",
    "import tensorcircuit as tc\n",
    "from tensorcircuit import shadows\n",
    "from functools import partial\n",
    "import pennylane as qml\n",
    "from tqdm import tqdm\n",
    "import basefunction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5b4a2",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95140cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_vectors = {\n",
    "    0: np.array([1, 0]),\n",
    "    1: np.array([0, 1]),\n",
    "    2: np.array([1, 1]) / np.sqrt(2),\n",
    "    3: np.array([1, -1]) / np.sqrt(2),\n",
    "    4: np.array([1, 1j]) / np.sqrt(2),\n",
    "    5: np.array([1, -1j]) / np.sqrt(2),\n",
    "}\n",
    "\n",
    "def large_scale_circuit(params, num_qubits, initial_state):\n",
    "    tc.set_backend(\"jax\")\n",
    "    c = tc.Circuit(num_qubits, inputs=initial_state)\n",
    "    n_layers = params.shape[0]\n",
    "    for layer in range(n_layers):\n",
    "        for qubit in range(num_qubits):\n",
    "            c.rx(qubit, theta=params[layer, qubit, 0])\n",
    "            c.ry(qubit, theta=params[layer, qubit, 1])\n",
    "            c.rz(qubit, theta=params[layer, qubit, 2])\n",
    "        for qubit in range(num_qubits - 1):\n",
    "            c.cnot(qubit, qubit + 1)\n",
    "    return c.state()\n",
    "\n",
    "def test_circuit(inistr, params):\n",
    "    num_qubits = len(inistr)\n",
    "    initial_state = basefunction.str2rhoinistr(inistr)\n",
    "    state_ode = large_scale_circuit(params, num_qubits, initial_state)\n",
    "    return state_ode\n",
    "\n",
    "def read_data():\n",
    "    try:\n",
    "        df = pd.read_csv('qubit_data.csv')\n",
    "        result_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            num_qubits = row['num_qubits']\n",
    "            rhoinput = np.array([int(x) for x in row['rhoinput'].split(',')])\n",
    "            params_flat = np.array([float(x) for x in row['params'].split(',')])\n",
    "            params = params_flat.reshape(10, num_qubits, 3)\n",
    "            result_dict[num_qubits] = {'rhoinput': rhoinput, 'params': params}\n",
    "        return result_dict\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found!\")\n",
    "        return None\n",
    "\n",
    "def shadow_creator(num_qubits, params, nshot):\n",
    "    resultin = basefunction.generate_random_sublists(nshot, num_qubits)\n",
    "    state_p = jax.vmap(test_circuit, in_axes=(0, None))(resultin, params)\n",
    "    tc.set_backend(\"jax\")\n",
    "    pauli_strings = tc.backend.convert_to_tensor(np.random.randint(1, 4, size=(nshot, num_qubits)))\n",
    "    status = tc.backend.convert_to_tensor(np.random.rand(nshot, 1))\n",
    "    @partial(tc.backend.jit, static_argnums=(3,))\n",
    "    def shadow_ss(psi, pauli_strings, status, measurement_only=True):\n",
    "        return shadows.shadow_snapshots(\n",
    "            psi, jnp.array([pauli_strings]), jnp.array([status]), measurement_only=measurement_only\n",
    "        )\n",
    "    vmap_shadow_ss = jax.vmap(shadow_ss, in_axes=(0, 0, 0), out_axes=0)\n",
    "    ss_states = vmap_shadow_ss(jnp.array(state_p), jnp.array(pauli_strings), jnp.array(status))\n",
    "    resultout = jax.vmap(basefunction.shadow2index2, in_axes=0)(ss_states, pauli_strings - 1)\n",
    "    return np.array(resultin), np.array(resultout)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = read_data()\n",
    "    for num_qubits in [2, 4, 6, 8]:\n",
    "        jax.config.update(\"jax_enable_x64\", True)\n",
    "        rhoinput = data[num_qubits][\"rhoinput\"]\n",
    "        params = data[num_qubits][\"params\"]\n",
    "        N = 100000\n",
    "        num_runs = 50\n",
    "        all_runs = []\n",
    "        for run_id in tqdm(range(num_runs), desc=\"Processing runs\"):\n",
    "            resultin, resultout = shadow_creator(num_qubits, params, N)\n",
    "            combined = np.column_stack((\n",
    "                np.full(N, run_id, dtype=int),\n",
    "                resultin,\n",
    "                resultout\n",
    "            ))\n",
    "            all_runs.append(combined)\n",
    "        final_data = np.vstack(all_runs)\n",
    "        np.savetxt(f'{num_qubits}qubits_performace_shadows.csv', final_data,\n",
    "                   delimiter=',',\n",
    "                   header='exp_id,resultin,resultout',\n",
    "                   fmt='%d',\n",
    "                   comments='')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
